{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Mask Detector_CNN_Julia.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yyyyyokoko/590FaceMaskDetection/blob/master/Mask_Detector_CNN_Julia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axYMiABmL5er"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX3HpfdLL5es",
        "outputId": "b20a85a6-e3f2-470e-8efc-ba5f32ba75ed"
      },
      "source": [
        "# number of files (images) that are in each folder\n",
        "# #train\n",
        "# print(\"The number of images labelled 'WithMask' in the training set:\",len(os.listdir('Train/WithMask')))\n",
        "# print(\"The number of images labelled 'WithoutMask' in the training set:\",len(os.listdir('Train/WithoutMask')))\n",
        "\n",
        "# #test\n",
        "# print(\"The number of images labelled 'WithMask' in the testing set:\",len(os.listdir('Test/WithMask')))\n",
        "# print(\"The number of images labelled 'WithoutMask' in the testing set:\",len(os.listdir('Test/WithoutMask')))\n",
        "\n",
        "# #val\n",
        "# print(\"The number of images labelled 'WithMask' in the val set:\",len(os.listdir('Validation/WithMask')))\n",
        "# print(\"The number of images labelled 'WithoutMask' in the val set:\",len(os.listdir('Validation/WithoutMask')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of images labelled 'WithMask' in the training set: 5000\n",
            "The number of images labelled 'WithoutMask' in the training set: 5000\n",
            "The number of images labelled 'WithMask' in the testing set: 483\n",
            "The number of images labelled 'WithoutMask' in the testing set: 509\n",
            "The number of images labelled 'WithMask' in the val set: 400\n",
            "The number of images labelled 'WithoutMask' in the val set: 400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YnAKp7wL5et"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(160, 160, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(50, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics =\"accuracy\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai5jNmYXLHDo",
        "outputId": "141db6a6-c99b-4174-d379-93a1317e06cd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 158, 158, 100)     2800      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 79, 79, 100)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 77, 77, 100)       90100     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 38, 38, 100)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 144400)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 144400)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                7220050   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 7,313,052\n",
            "Trainable params: 7,313,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iE8tOIcMIBv",
        "outputId": "b1a0e229-6812-4c1a-ac42-01bef5db4b91"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# train_dir = '/content/drive/My Drive/ColabNotebooks/Face Mask Dataset/Train/'\n",
        "train_dir = '/content/drive/My Drive/ColabNotebooks/Face Mask Dataset/Validation/'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIn8dEKFL5et",
        "outputId": "6f2669d8-ee34-4c04-9b18-38c106aabaac"
      },
      "source": [
        "# train_dir = \"C:/Users/zhuyi/Documents/ANLY590_DEEP/project/Train\"\n",
        "train_data = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.10,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.15,\n",
        "        rescale=1./255,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2)\n",
        "\n",
        "train = train_data.flow_from_directory(directory=train_dir,target_size=(160,160),\n",
        "                                          class_mode=\"categorical\",batch_size=32,subset = \"training\")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid = train_data.flow_from_directory(directory=train_dir,target_size=(160,160),\n",
        "                                          class_mode=\"categorical\",batch_size=32,subset=\"validation\")\n",
        "\n",
        "# train_generator = train_data.flow_from_directory(train_dir,batch_size=10,target_size=(160, 160))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 526 images belonging to 2 classes.\n",
            "Found 130 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEyNFVNUL5et"
      },
      "source": [
        "# val_dir = '/content/drive/My Drive/ColabNotebooks/Face Mask Dataset/Validation/'\n",
        "# val_data = ImageDataGenerator(rescale=1.0/255)\n",
        "# val_generator = val_data.flow_from_directory(val_dir,batch_size=10,target_size=(160, 160))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPW3pdcDL5et"
      },
      "source": [
        "# checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
        "checkpoint = ModelCheckpoint(\"moblenet_facemask.h5\",monitor=\"val_accuracy\",save_best_only=True,verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHIFcxPHL5et",
        "outputId": "20c671d4-36fc-45e3-eace-5a74437a51ce"
      },
      "source": [
        "# history = model.fit_generator(train_generator,\n",
        "#                               epochs=10,\n",
        "#                               validation_data=val_generator,\n",
        "#                               callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "history = model.fit_generator(generator=train, validation_data=valid,\n",
        "                               callbacks=[checkpoint],\n",
        "                              epochs=5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9183\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.91538, saving model to moblenet_facemask.h5\n",
            "17/17 [==============================] - 61s 4s/step - loss: 0.2161 - accuracy: 0.9183 - val_loss: 0.1930 - val_accuracy: 0.9154\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9563\n",
            "Epoch 00002: val_accuracy improved from 0.91538 to 0.94615, saving model to moblenet_facemask.h5\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.1381 - accuracy: 0.9563 - val_loss: 0.1869 - val_accuracy: 0.9462\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9677\n",
            "Epoch 00003: val_accuracy did not improve from 0.94615\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.1133 - accuracy: 0.9677 - val_loss: 0.2272 - val_accuracy: 0.9308\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9658\n",
            "Epoch 00004: val_accuracy improved from 0.94615 to 0.95385, saving model to moblenet_facemask.h5\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.1138 - accuracy: 0.9658 - val_loss: 0.1622 - val_accuracy: 0.9538\n",
            "Epoch 5/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.9601\n",
            "Epoch 00005: val_accuracy did not improve from 0.95385\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.1253 - accuracy: 0.9601 - val_loss: 0.1648 - val_accuracy: 0.9385\n",
            "Epoch 6/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9620\n",
            "Epoch 00006: val_accuracy did not improve from 0.95385\n",
            "17/17 [==============================] - 63s 4s/step - loss: 0.0900 - accuracy: 0.9620 - val_loss: 0.1677 - val_accuracy: 0.9308\n",
            "Epoch 7/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9658\n",
            "Epoch 00007: val_accuracy did not improve from 0.95385\n",
            "17/17 [==============================] - 64s 4s/step - loss: 0.1084 - accuracy: 0.9658 - val_loss: 0.1422 - val_accuracy: 0.9538\n",
            "Epoch 8/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9772\n",
            "Epoch 00008: val_accuracy did not improve from 0.95385\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.0879 - accuracy: 0.9772 - val_loss: 0.2778 - val_accuracy: 0.9077\n",
            "Epoch 9/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9601\n",
            "Epoch 00009: val_accuracy did not improve from 0.95385\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.1409 - accuracy: 0.9601 - val_loss: 0.1979 - val_accuracy: 0.9308\n",
            "Epoch 10/10\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9487\n",
            "Epoch 00010: val_accuracy improved from 0.95385 to 0.96154, saving model to moblenet_facemask.h5\n",
            "17/17 [==============================] - 60s 4s/step - loss: 0.1618 - accuracy: 0.9487 - val_loss: 0.1588 - val_accuracy: 0.9615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZNVb2gaY0Ys",
        "outputId": "6407d53f-5cac-4b18-ce2d-1890f4a81ae7"
      },
      "source": [
        "model.evaluate_generator(valid)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-37-72167c2d045e>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16063416004180908, 0.9538461565971375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgV5BqW4a4Sp",
        "outputId": "8217529a-82bb-41a8-a32a-c1128458dddc"
      },
      "source": [
        "pred = model.predict_classes(valid)\n",
        "pred[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-38-7d8f052b73a7>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-zrH6L4L5et"
      },
      "source": [
        "# model.save(os.path.join(\"C:/Users/zhuyi/Documents/ANLY590_DEEP/project\",'model.h5'))\n",
        "model.save(\"/content/drive/My Drive/ColabNotebooks/face_mask_julia_cnn_new.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp9A1FMIOde8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6krmQwlOdhi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEk8apiXOdj1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47-hYHgqOdmf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKTFcenhOdpE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5NaNdSnL5et"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYb91xX_L5et"
      },
      "source": [
        "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMwjznEZL5et",
        "outputId": "9f66d0f3-56ba-45bf-f503-ee4d24fb7100"
      },
      "source": [
        "labels_dict={0:'without_mask',1:'with_mask'}\n",
        "color_dict={0:(0,0,255),1:(0,255,0)}\n",
        "\n",
        "size = 4\n",
        "webcam = cv2.VideoCapture(0) #Use camera 0\n",
        "\n",
        "# We load the xml file\n",
        "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "while True:\n",
        "    (rval, im) = webcam.read()\n",
        "    im=cv2.flip(im,1,1) #Flip to act as a mirror\n",
        "\n",
        "    # Resize the image to speed up detection\n",
        "    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
        "\n",
        "    # detect MultiScale / faces \n",
        "    faces = classifier.detectMultiScale(mini)\n",
        "\n",
        "    # Draw rectangles around each face\n",
        "    for f in faces:\n",
        "        (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n",
        "        #Save just the rectangle faces in SubRecFaces\n",
        "        face_img = im[y:y+h, x:x+w]\n",
        "        resized=cv2.resize(face_img,(150,150))\n",
        "        normalized=resized/255.0\n",
        "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
        "        reshaped = np.vstack([reshaped])\n",
        "        result=model.predict(reshaped)\n",
        "        #print(result)\n",
        "        \n",
        "        label=np.argmax(result,axis=1)[0]\n",
        "      \n",
        "        cv2.rectangle(im,(x,y),(x+w,y+h),color_dict[label],2)\n",
        "        cv2.rectangle(im,(x,y-40),(x+w,y),color_dict[label],-1)\n",
        "        cv2.putText(im, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
        "        \n",
        "    # Show the image\n",
        "    cv2.imshow('LIVE',   im)\n",
        "    key = cv2.waitKey(10)\n",
        "    # if Esc key is press then break out of the loop \n",
        "    if key == 27: #The Esc key\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-23-86a0855a7334>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# detect MultiScale / faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Draw rectangles around each face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpXRHPxfL5et"
      },
      "source": [
        "webcam.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI2k5nivL5eu"
      },
      "source": [
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}